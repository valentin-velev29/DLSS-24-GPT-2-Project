{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8909238,"sourceType":"datasetVersion","datasetId":5356937}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm  # Import tqdm\n\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datasets import load_dataset\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, set_seed\nfrom collections import Counter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T21:55:00.906639Z","iopub.execute_input":"2024-07-08T21:55:00.906994Z","iopub.status.idle":"2024-07-08T21:55:07.036738Z","shell.execute_reply.started":"2024-07-08T21:55:00.906964Z","shell.execute_reply":"2024-07-08T21:55:07.035941Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/checkpoint1/checkpoint1.csv') # replace with your path\ndf","metadata":{"execution":{"iopub.status.busy":"2024-07-08T21:55:18.848552Z","iopub.execute_input":"2024-07-08T21:55:18.848946Z","iopub.status.idle":"2024-07-08T21:55:41.512278Z","shell.execute_reply.started":"2024-07-08T21:55:18.848914Z","shell.execute_reply":"2024-07-08T21:55:41.511270Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Set random seeds for reproducible and consistent results\nset_seed(42)\n\ncheckpoint = 'siebert/sentiment-roberta-large-english'\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n\nclass ScamDataset(Dataset):\n    def __init__(self, texts, tokenizer, max_length=512):\n        self.texts = texts\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=self.max_length)\n        return inputs\n\n# Move the model to the GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\nmodel.to(device)\nmodel.eval()  # Set the model to evaluation mode\n\n# Create a Dataset and DataLoader\ntexts = df['text'].copy()\ndataset = ScamDataset(texts, tokenizer)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n\npredictions = []\n\nwith torch.no_grad():\n    # Wrap the dataloader with tqdm to track progress\n    for batch in tqdm(dataloader, desc=\"Classifying\"):\n        # Move batch data to GPU\n        inputs = {key: val.squeeze(1).to(device) for key, val in batch.items()}\n        outputs = model(**inputs)\n        logits = outputs.logits\n        batch_predictions = torch.argmax(logits, dim=1).tolist()\n        predictions.extend(batch_predictions)\n\nprint(\"Classification complete.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T21:56:25.989537Z","iopub.execute_input":"2024-07-08T21:56:25.989938Z","iopub.status.idle":"2024-07-08T21:57:15.018090Z","shell.execute_reply.started":"2024-07-08T21:56:25.989909Z","shell.execute_reply":"2024-07-08T21:57:15.016823Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-07-08 21:56:27.807516: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-08 21:56:27.807614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-08 21:56:27.945423: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/256 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e0d129289a04e16b09b0863a9916415"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a68fa14002fa45989105b92ea5802936"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45cb0dd739de4810ae707073af34b900"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd13b1042a2748289a67c55195121a6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edc253a7e9bc45d98f03cb4f91f98322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fc91fbe924b4a65a883bb89fe13345a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"name":"stdout","text":"cuda\n","output_type":"stream"},{"name":"stderr","text":"Classifying:   0%|          | 14/65440 [00:27<35:04:54,  1.93s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m     41\u001b[0m         logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m---> 42\u001b[0m         batch_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mextend(batch_predictions)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"df['label'] = predictions\ndf.to_csv('second_preprocess.csv', index=False) # Please send me this file","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split dataset if it takes too long (irrelevant for you)","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/checkpoint1/checkpoint1.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T21:57:45.083955Z","iopub.execute_input":"2024-07-08T21:57:45.084340Z","iopub.status.idle":"2024-07-08T21:58:01.359846Z","shell.execute_reply.started":"2024-07-08T21:57:45.084310Z","shell.execute_reply":"2024-07-08T21:58:01.358983Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"split = int(len(df)/2)\nprint(split)\ndf1 = df.iloc[:split]\ndf2 = df.iloc[split:]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T21:58:12.152203Z","iopub.execute_input":"2024-07-08T21:58:12.152559Z","iopub.status.idle":"2024-07-08T21:58:12.158370Z","shell.execute_reply.started":"2024-07-08T21:58:12.152533Z","shell.execute_reply":"2024-07-08T21:58:12.157400Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"1047038\n","output_type":"stream"}]},{"cell_type":"code","source":"df1.to_csv('senti_split1.csv', index=False)\ndf2.to_csv('senti_split2.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T22:00:15.251209Z","iopub.execute_input":"2024-07-08T22:00:15.251613Z","iopub.status.idle":"2024-07-08T22:00:51.864974Z","shell.execute_reply.started":"2024-07-08T22:00:15.251584Z","shell.execute_reply":"2024-07-08T22:00:51.863539Z"},"trusted":true},"execution_count":11,"outputs":[]}]}